To improve the convergence of GAQA, we choose to upgrade the reproduction-related parameters according to the predication of searching overhead.
To guide the searching direction of GAQA, a fitness function should be designed to evaluate the quality of each solution.
GAQA has achieved a Theta increase in ASR, and respectively decreased AQ and MQ by Theta and Theta, compared with the three black-box methods .
In Section V, extensive experiments are conducted to evaluate the performance of proposed method.
Theta and Theta are limited to the number of population Theta.
Adversarial Training , Gradient Masking  and Input Transformation  and Theta.
Theta, Theta and Theta.
Therefore, our method has greater ASR and lower MQ on different neural network architectures.
The average MCSD of GAQA is  Theta, Theta, Theta, Theta and Theta of those of APGD-CE, ZOO, Square, DeepFool, and GenAttack, respectively.
The high-quality genes from low-score chromosomes will be filtered out, whereas the high-quality genes from high-score chromosomes are mostly kept for the next searching iteration.
Some existing attacks  consider to restart the searching by dropping all the perturbations, which is waste of the searching efforts.
But some white-box algorithm may have different coverage compared with black-box attack.
Theta represents the existing attack methods.
Theta is the dimension of input Theta, Theta is the bound of Theta-norm to escape human perception.
Based on the evolution matrix for the first three generations, the solutions of 4th generation can be produced.
Adversarial example  attacks are typically launched by maliciously crafted inputs, and aim to let DNN models to misbehave.
Since Theta is much less than Theta and Theta, time complexity of PSO-Jump can be obtained as Theta.
To improve the convergence, GAQA conducts the adaptation operation to update the reproduction-related parameters according to equations.
As a supplementary work, this paper approaches to implement black-box AE attacks on defensive DNN models deployed in servers like MLaaS.
GAQA is designed to pick up certain top perturbations  for reassembling operations.
Normalized Euclidean Distance : the difference between the original images and the adversarial images.
For simplicity, we calculate them with the same following equation.
Ordinary Differential equationuations   on CIFAR-10: imposing constraints to ensure that all eigenvalues of the Jacobian matrix of the neural ODE layer have negative real parts, when each classification class converges to its own equilibrium points.
Jumping process  will further used to generate non-local optimal solutions when the number of iterations reaches at the predefined threshold Theta.
IT is devised to reduce the model sensitivity to perturbations on original images.
Different to existing works, in this paper we are interested in the generation of AEs for DNNs with defensive mechanisms.
Perturbation-varied reproduction is designed to generate Theta new perturbations, thus it costs Theta.
It would be good policy to produce new offspring  in the direction of perturbation-direction of input data.
APGD-CE and DeepFool are white-box attack methods while ZOO, Square-Attack and GenAttack are black-box attack methods.
Illustration of PSO-based perturbations evolution.
Theta is the best solution  of all solutions in the Theta-th iteration.
The mutation probability Theta and shuffling probability Theta also need to be updated with the predicted Theta.
Well-designed evolutionary algorithms have been used for image generation , image classification   and neural architecture search .
For example, given Theta as Theta, the expected number of chosen chromosomes can be calculated to be Theta for the population with Theta solutions.
For the evolving procedure, PSO-Jump will update the position of each particle for Theta times .
As a flexible searching framework, GA can be designed to support both single-objective and multi-objective optimization problems.
Incorporating with gradient information, decision boundary-based methods are also developed, which can push the data to the decision boundary to realize misclassification of images.
Our method achieves a Theta increase in ASR and respectively decreases AQ and MQ by Theta and Theta compared with the three black-box methods.
Theta indicates the standard deviation of Theta and its eight adjacent points.
Revisiting Adversarial Training   on ImageNet: using a weaker and cheaper adversary by FGSM to train a defensive model with higher robust accuracy.
We have conducted to extensive experiments to evaluate the efficiency of our method.
Meanwhile, our approach has the same ASR with the white-box attack methods while our method has lower queries compared with other black-box attack methods.
It may be because that Genattack has no jump operator and adaptive process.
Another way to defend against attack is to construct a robust model .
Particle Swarm Optimization  can obtain optimized solutions in a large stochastic searching space by imitating the food-finding process of a swarm of birds .
The quality of population members is evaluated by a fitness function.
As a prominent branch of AE attacks, a great number of white-box attacks have been developed .
On the contrary, black-box attacks are assumed to be zero-knowledge of architecture, parameters or any other settings of targeted DNN models.
In Stage , new solutions  will be generated via Reproduction operators including Perturbation-varied reproduction, Block-based crossover, and Shuffle-based crossover.
Theta.
ResNet is a widely used neural network, which contains identity short-cut connections.
After that, GAQA will conduct the superiority-related probabilistic selection on the current perturbation solutions , wherein the inferior solutions will be deleted from the current generation .
With the purpose of preventing the disappearance of elite solutions and ensuring the non-decrease of the fitness function, the solutions with high fitness values are generally expected to be kept in the next generation.
Our method has average Theta, Theta, Theta, Theta and Theta reduction in NED, respectively, compared with APGD-CE, ZOO, Square, DeepFool and GenAttack.
Theta is related to the speed Theta in 3rd generation, the best-so-far perturbation for the first particle , and the best perturbation in the 3rd generation .
We assume the distance between any two consecutive perturbations are the same.
Section II describes preliminaries work.
Following that, BIM   is further designed to generate better AEs by iteratively using FGSM.
Besides the objective of attack effectiveness, we need to evaluate the attack coverage ratio of the proposed black-box attack method.
Assume that the defenders know the model structure and can deconstruct the DNN model to get the weight parameters.
GM is to force DNN models to have zero-close gradients, thus reducing the perturbation sensitivity to DNN models.
However, our GAQA has fewer queries compared with the three black-box attack methods.
Our approach is attacking a defensive model.
In this paper, we propose the elites-preferred probabilistic selection to choose solutions for the coming iterations in our GAQA.
Therefore, we only need to optimize the second part to find perturbations with high attack evasiveness.
The query operation of the victim model can be defined as the function Theta, within which Theta returns the confidence of recognizing input Theta as class label Theta.
Some white-box attacks only search at one convex space which contains Theta.
Average Queries : the average query times in the three experiments.
For the situation of successful AE attack, the value of the first part is fixed to  Theta according to the Theta operation on it.
PSO is designed to an iterative searching algorithm by imitating the food-finding process of a flock of birds.
Afterwards, PSO-Jump will evaluate the fitness value Theta, and check whether it is greater than Theta .
The six attack methods can be divided into three types: GAQA, Genattack and others.
PSO for our AE search problem.
Since this paper only considers to generate adversarial examples for images of general size, it would be a challenging work to extend our searching framework to support the generation of adversarial examples for super large images.
Due to the strong randomness of the shuffle-based-crossover, shuffle-based-crossover expands the width of the search scope instead of the depth of the scope.
We choose different neural network architectures including Mlp-mixer , Swim-transformer  and ResNet  to test the effectiveness of our method on the non-defensive models on ImageNet with Theta norm.
He likes dogs.
The best solutions for all particle positions  are also updated according to the fitness evolution matrix.
Sort Theta by the decrease order of fitness.
As the future work, it is worthy of doing the following researches.
We define Theta as mean convolution standard deviation to evaluate the high frequency signals of AE, which calculates the standard deviation of a pixel point and its eight adjacent points.
Theta is designed to decrease with the increase of Theta to guarantee the high probability to select elite solutions, as shown in equation.
With the purpose of alleviating the vulnerability to AE attacks, certain mechanisms are emerging to improve the defensive performance of DNNs including AE detection and recognition , adversarial training of DNNs  and image compression  in the image domain.
For instance, the produce of Theta depends on the solution Theta in the position Theta of 3rd generation and the speed Theta according to equation.
Section V-B.
We evaluate the effectiveness of the proposed method on defensive models and non-defensive models in Section V and Section V.
The first part is related to the objective of attack effectiveness, whereas the second part focuses on the objective of attack evasiveness.
Update adaptive parameters Theta, Theta, Theta via equation.
It has the high probability to increase the fitness value if changing the perturbation of  Theta  towards the direction Theta.
Theta is increased after the PSO-Jump process.
We propose a GA-based query-efficient attack method to generate image AEs to breakthrough victim models with defensive mechanisms.
First, the solutions in the current generations are sorted by the decrease order of their fitness values.
PSO-Jump will terminate the PSO evolving when generating one effective AE.
UD, WDM and ODEs are based on CIFAR10.
Similar to card shuffling in card-play games, we randomly select the genes from their fathers to generate new solutions.
Given a clean image, the corresponding AE depends on the perturbation on each pixel of the image.
When applying mutation on the set of perturbations, it will result in certain high-quality genes and inferior genes.
Therefore, our approach has stronger searching capacity and higher ASR.
The adversaries have the right of accessing to DNNs, and mostly exploit back-propagation methods to obtain the gradient information of DNN models, thus generating white-box AEs to threaten the victim models.
During the searching iteration, the parameters related reproduction operators need to be updated.
In natural selection, the superior offspring may be born with elite fathers and inferior fathers.
This section introduces the preliminaries.
Consequently, PSO-Jump will take the time overhead of Theta.
Compared with the three black-box attack methods, our method has greater ASR and lower MQ.
However, due to the weak interpretability, DNNs has the inherent vulnerability to Adversarial Example  attacks  .
Each solution could have the average perturbation range as Theta for Theta solutions of Theta.
We start our experiments on the CIFAR-10 dataset with Theta norm.
Mlp-mixer is a traditional neural network, which consists of an input layer, several hidden layers and an output layer.
Consequently, we define the fitness  of each perturbation solution by equation.
In this paper, we use GA to address the AE generation problem since it can be inherent formulated as constrained optimization problems.
Black-box AE attacks are also seriously threatened to DNNs .
We can conclude that our GAQA is suitable to check the robustness of neural networks.
Similarly, we consider to choose the solutions in elite population and inferior population to implement the shuffle-based crossover.
Compared with the black-box methods, our method has Theta increase in ASR.
We use Theta and Theta to denote the set of elite solutions and the set of inferior solutions in the Theta-th generation, respectively.
Deep Neural Networks  have been immensely deployed into artificial intelligence-driven applications , ranging from identification recognition to environment surveillance and to smart robot applications.
Given a set of clean  images and the attack method A, Theta is used to denote the set of AEs which successfully attack the victim model.
Due to the inherent characteristics of gradient-free and adaptive query, we only need to deal with detection-based defensive mechanisms based on input transformation while ignoring the defensive mechanisms of adversarial training and gradient masking.
We assume to predict the remaining iterations when GAQA has searched for 100 iterations.
From another point of view, defenders could reduce the decentered neighborhood.
A Defensive DNN model is defined as Theta, which is able to alleviate the impact of perturbed input Theta with the defensive policy Theta.
Given Theta as the minimal value of attack effectiveness , the fitness function is transformed to optimize the attack evasiveness while guaranteeing the attack is effective.
CR results on the two defensive models.
For comparison, we valuate each operator of GAQA on the non-defensive model  and the defensive model .
Our method has average Theta, Theta, Theta, Theta and Theta reduction in NED, respectively, compared with APGD-CE, ZOO, Square, DeepFool, and GenAttack.
GM is also cost-expensive and not suitable for black-box attacks.
The objective of attack coverage could not be represented in the fitness function, since it depends on the experimental comparison with other attack methods.
However, these methods are query-intensive and computation-expensive, thus limiting their applications in real-world applications.
The compression phase Theta will compress an input image.
APGD-CE , ZOO , Square-Attack , DeepFool , GenAttack .
Given the benign input Theta with the class label as Theta, the perturbed Theta is defined as an AE if misclassified to the label Theta.
Initiate the perturbation solutions Theta via equation.
Unlabeled Data   on CIFAR-10: using unlabeled data to bridge the sample complexity gap between standard and robust classification.
We choose LTD  and FDA  as the victim neural networks.
Then PSO-Jump calculates the perturbation of Theta according to  Theta and Theta  .
First, the experimental setup is given in Section V.
Theta is the best solution  of the Theta-indexed solutions for the first Theta iterations.
As one popular method, Genetic Algorithm  is popular to search optimal solutions for constrained optimization problems.
The crossover and mutation operator are designed to increase the diversity of population while the selection operator is used to find globally better solutions Theta in the search space.
ASR, MQ and AQ comparisons on different datasets.
To make AE attacks imperceptible, according to equation.
Moreover, removing the initialize-population will increase MQ by Theta with a Theta drop in ASR.
Although Genattack is a genetic algorithm, it has poor performance.
In Section IV, the detailed design of query-efficient GA attack is given.
Minimum Attack Set : the minority attack methods set which could cover other attack methods completely.
In case of non-defensive models, our method can successfully attack state-of-the-art network architectures including Mlp-mixper and Swim-Transformer.
Defenders  usually use white-box attack methods to generate adversarial examples because they have access to the parameters and structure of their model.
Theta is the perturbation bound of Theta-norm.
We can observe that Theta will exceed the Theta according to equation.
Low Temperature Distillation   on CIFAR-100: using the knowledge distillation framework to generate the desired soft labels.
We use CIFAR-10, CIFAR-100 and ImageNet to test evaluate the effectiveness of our method on ResNet with Theta norm.
With the updates of searching parameters, GAQA can adaptively work during the searching iterations and consequently quickly converge to find the near-optimal global solutions.
Similarly, the evolutions of Theta, Theta and Theta for the 4th generation can be conducted.
The experiment indicates that genetic algorithm has a strong searching capacity.
Considering the linear characteristics of DNNs, FGSM  is proposed to generate AEs using on-step gradient updation on image pixels.
In addition, we use the 0-1 matrix Theta to represent the gene-shuffling selection of each selected father chromosome, where each element Theta of Theta  is set to 1 with the probability of Theta.
The perturbation matrix for each father solution is first split into a number of square blocks.
Therefore, we can conclude that the PSO-Jump of our GAQA is effective.
To obtain the fitness value , we need to sort the confidence values of Theta labels .
According to the procedure of GAQA, the time overhead consists of eight parts during the GA search framework.
Due to high time overhead to find the optimal Theta for each solution Theta, we choose to search for the near-optimal Theta only for Theta in each generation, thus reducing the complexity of the query process.
GAQA has more queries than the two white-box methods .
Note that PSO-Jump is described in the following paragraph.
In this paper, we have made efforts to generate adversarial examples for defensive DNN models deployed in the image-related intelligent systems.
The DNN model Theta is trained based on the training data set with Theta labeled inputs Theta, where Theta is an input instance and Theta is its ground-truth class label.
This is because the white-box attacks have the gradient information to modify the perturbation direction whereas our method explores the direction.
Although white-box attacks have been evaluated successful, they cannot achieve high attack performance in practical applications where the information of victim models and training data are definitely not disclosed to the adversarial attackers.
Theta and model classify it into Theta, which is called positive examples.
For image classification tasks, well-designed AEs is capable of fooling DNN models with wrong predictions while being imperceptible to human naked eyes.
We expect to initiate the perturbations of all solutions to fill the searching space uniformly.
The Theta-th solution in Theta-th generation  with higher fitness Theta function values are more likely to be selected in the next generation Theta.
Therefore, GAQA has a better attack capacity even in a poor start position, but it will take more steps to achieve the same performance.
Although we have introduced certain mechanisms to avoid the searching into local optimal space, there still has the possibility to fall into the local optimum after a large number of evolving iterations.
However, the research to generate AEs using evolutionary algorithms is seriously overlooked for defensive DNNs.
Removing the PSO-Jump will increase MQ and AQ.
Note that, each element of the matrix chromosome Theta can change independently.
In other words, the predicted Theta depends on the so-far optimal fitness and the number of iterations.
PSO-Jump is checked whether to be invoked by comparing Theta to the predefined threshold Theta .
The specific values of Theta and block size will be adaptively changed during each iteration, thus improving the convergence of QAGA.
For any point Theta, it satisfies equation.
Considering a complex DNN Theta  with numerous parameters, it has a powerful  ability to fit the input signal.
Due to the explosive search space, it is extremely difficult to find the optimal AE to attack defensive DNN models.
The better Theta of offspring will be remained after superiority-driven probabilistic selection.
To make the attack more practical, we exploit query-based black-box method to generate image AEs.
To facilitate the attack in practice, we presented a query-efficient black-box method, named GAQA, to generate adversarial examples.
In other words, the requirement satisfied adversarial example can not be generated even with high time overhead.
According to the pseudo code of PSO-Jump, the main time overhead depends on the Theta iterations to calculate the speed Theta and the perturbation Theta for particle Theta, which takes time overhead of Theta.
Specifically, the calculation of Theta can be referred to equation.
The average MCSD of GAQA is Theta, Theta, Theta, Theta and Theta of those of APGD-CE, ZOO, Square, DeepFool, and GenAttack, which means that our GAQA has a great evasiveness on the big-scale datasets.
In this paper, we aim to fast generate AEs via query-based black-box method to attack defensive DNNs deployed in MLaaS.
Along with the fast development of AE attacks, the robustness of DNNs has received increasing concerns.
Since GAQA can generate better adversarial examples according to equation.
Then, this paper proposes a query-efficient AE attack based on Genetic Algorithm  and Particle Swarm Optimization  to address the perturbation optimization problem.
Swim-transformer is a new neural network based on the NLP transformer.
Theta, Theta or Theta.
Since the non-defensive models have many weaknesses, attack methods have fewer queries compared with attacking the defensive models.
To sum up, our method achieves better performance on the non-defensive models according to the experimental results of different neural network architectures, Theta norm and datasets, which demonstrates that our method is suitable for different situations.
This could guarantee all genes of Theta are independently inherited from fathers.
ASR, MQ and AQ comparisons on different Theta norm.
This is reasonable since white-box attacks need to know the detail information of model architecture, model parameters and training data of the victim DNN models.
Theta is decreasing with the growing of Theta.
We chose Theta and Theta norm to evaluate the effectiveness of our method on CIFAR-10 with ResNet.
For the situation of failed AE , Theta is less than zero.
Based on the prediction of searching iterations, we introduce predication-based adaptation for reproduction-related parameters to speed up the search convergence, and design PSO-based jump to avoid the search stuck at local optimum.
PSO-Jump finally will return the updated perturbations Theta to GAQA for GA-based evolution .
In this section, we conduct the ablation experiments to test the effectiveness of our method.
Fixing Data Augmentation   on CIFAR-100: using generated examples to provide a greater diversity of augmentations that help enhance the image manifolds and allow adversarial training.
First, GAQA takes Theta to initialize the perturbation population.
The smaller NED means that the adversarial examples generated by our method are more similar to the original images.
The ASRs of all three types have no overlap, which may be because the bigger scale datasets have the larger search spaces.
Specifically,  Theta can be calculated according to equation.
To sum up, our method achieves good performance on the defensive models according to the experimental results on CIFAR-10, CIFAR-100 and ImageNet.
The effectiveness of attack methods is evaluated by seven metrics.
GAQA initializes the perturbation population and search-related parameters .
Less MCSD means that our adversarial examples have less high frequency signals, which makes our method unlikely to be detected by identification modules or cleared by the compression modules.
Adversarial example recognition relies on two networks: identification and elimination  model.
However, keeping certain weak solutions into the next iteration is also absolutely necessary since they also have certain superior genes in their chromosomes.
Benchmark-based experiments on CIFAR-10, CIFAR-100 and ImageNet-1K are conducted to evaluate the efficiency of our method in both defensive and non-defensive scenarios.
Theta must be limited.
Image compression used to reduce input space.
In addition, most of existing AE attacks including both white-box and black-box methods ignore to generate AEs for defensive DNNs in the scenarios of MLaaS.
PSO-Jump, probabilistic-selection and block-based-crossover are used to decrease the query number, leading to a performance degradation on the non-defensive models.
We use three dataset including CIFAR-10, CIFAR-100 and ImageNet to evaluate the effectiveness of the proposed method on defensive models and non-defensive models.
This is a high-dimension coordinate system in input space.
Query stage, the adversarial examples  are feed to the victim model to get the corresponding confidence values of prediction classes.
GAQA can reduce Theta, Theta, Theta, Theta and Theta in NED, respectively, compared with APGD-CE, ZOO, Square, DeepFool, and GenAttack in three defensive models.
Finally, Section VI concludes the paper with future work.
We assume Theta as the Theta-th solution in Theta-th generation and  Theta as the Theta-th solution in Theta-th generation.
Theta decrease in the number of queries.
This paper will focus on dealing with IT-based detection and defense within MLaaS.
Adversarial training is an useful tool to build a stronger DNN, where defenders could use attack method to generate adversarial examples and put them into training process.
Similar to GA's searching framework, GAQA is designed to iteratively evolve the perturbations on clean images, with the purpose to successfully attack the defensive victim DNN model.
Inspired by Genetic Algorithm , one of the most flexible and efficient searching evolution algorithm, in this section we propose GA-based Query-efficient Attack  to search for the best adversarial examples, in which AE-specific components are designed to speed up the evolution procedure and PSO-based jumping is incorporated to avoid local optimal solutions.
However, it is not suitable for the search framework of GAQA, because we always expect to keep the perturbations better fitness values even with mutation operations.
Otherwise, PSO-Jump continues the evolving procedure by updating Theta  and  Theta by Theta .
The two white-box attack methods  and our method can achieve Theta ASR.
Mean Convolution Standard Deviation : the smoothness of a adversarial image.
PSO-Jump, which takes a set of perturbation particles  as the input.
In general, evolutionary operators of selection, crossover and mutation are utilized to breed the next-generation population.
Median Queries :  the median query times in the three experiments.
We chose UD , WDM , ODEs  as the victim neural networks.
TLM  and RAT  as the victim models.
When the estimated steps exceed the threshold, the iterative process of PSO will be performed.
DNNs are designed to learn the high-level features using layer-by-layer data processing in high-dimension space, similar to the information flow of neurons in living organisms.
Due to the bigger search space of the large-size images, our method needs more queries to estimate the evolving direction.
The average MCSD of GAQA is Theta, Theta, Theta, Theta and Theta	of those of APGD-CE, ZOO, Square, DeepFool, and GenAttack, respectively.
Comparing with white-box attacks, they are more practical since they are assumed to be zero-knowledge of model architecture, parameters and the training data.
From the view of defense, it would be interesting to find the weakness of the deployed models using our method, and then fix the vulnerability to enhance the model robustness.
Theta and Theta.
Compared with current black-box methods, GAQA can effectively generate optimal perturbations on images and significantly decrease the number of queries to the victim model.
We choose Mlp-mixer , Swim-transformer  and ResNet  as the non-defensive models.
Theta is the maximal fitness value for all solutions according to equation.
Second, ablation study is presented to demonstrate the efficiency of each step of our GAQA in Section V.
LTD and FDA are based on CIFAR100.
Well Designed Model   on CIFAR-10: reducing capacity via depth or width at the deeper layers to improves adversarial robustness.
Adaptive mutation is designed to improve the diversity of the perturbations in Stage .
Theta is calculated by the following equation.
Based on the predicted Theta, Theta can be calculated by the following equation.
To implement white-box attacks, the adversarial attackers are assumed to know the full knowledge of model architecture, model parameters and training data of the victim DNN models.
Before the searching iteration, GAQA needs to construct the initial population.
Let Theta, searching with multi-granularity in the direction of Theta can help to find the optimal solution.
In addition to the strong ability of model prediction, we assume the victim DNN models are deployed with certain defensive protections to ensure their robust to adversarial attacks.
Different to traditional GA, adversarial example-specific reproduction operators are well designed to improve search efficiency of GAQA.
The values of  Theta and Theta will increase with the number of Theta growing.
It is of critical importance to construct the initial population Theta with the purpose of improving the search efficiency.
Defenders  could use image compression to reduce high-dimensional data to low-dimensional data.
Probabilistic selection will only take Theta time cost.
It indicates that our method with well-designed operators has a strong searching capacity in vast space.
Attack Successful Ratio : the ratio of incorrect classification in the input images.
FL and RAT are based on ImageNet.
The newly generated solution Theta in Theta-th iteration is related to the solution Theta and its moving speed , which is formally expressed by equation.
Section presents the threat model and formulate the design to a multi-objective optimization problem.
In other words, the objective of attack evasiveness needs to be improved only if the AE attack is effective.
AT is expensive to obtain holistic AEs and cannot guarantee its effectiveness facing emerging AEs, especially black-box generated AEs.
To sum up, removing any operator will lead to the drop of ASR in the non-defensive or defensive models, which demonstrates that each operator of GAQA plays a role in the searching process.
Genattack has the smallest CR among the six attack methods, which may be because it has no adaptive function and well-designed reproduction process.
As the primary group of machine learnings, Deep neural networks  are immense popular in regression tasks and classification tasks of emerging intelligent systems, especially for image processing systems.
First, the number of discrete perturbations, Theta, needs to be refined.
ASR, MQ and AQ comparisons on different nerual network architectures.
Therefore, this operator helps GAQA to find the adversarial examples quickly.
In contrast to white-box attack, block-box attack has a wider search space, because it has no knowledge of the specific distribution of the high-dimensional space around the original example.
To deceive the perception of human eyes, each element of the perturbation has the bound of Theta.
Then, we assign a filter probability for each solution.
The identification and elimination strategy is applied to defend against potential adversarial example attacks.
The original training dataset is unknown to defenders, meaning that the defense strategy cannot be designed from the perceptive of the dataset.
Our method has more MQ and AQ on the large-size datasets.
More specific, this paper aims to deploy a query-based gradient-free black-box attack on MLaaS, which can adaptively upgrade the attack strength of adversarial inputs according to the returned confidence values of all classes.
Therefore, it is important for defenders to find  adversarial examples as much as possible.
Therefore, it is practical to set a threshold  for the intolerable searching iterations.
Given the input image Theta having the width Theta and the height Theta, Theta the MCSD can be obtained by equation.
The three black-box attack methods  and our method have higher MQ and AQ, since they need to estimate the evolution direction through the query model.
Since feature-squeezing and image-compress are two most widely used input transformation policies, we must try our best to guarantee the generated AEs can stealthy pass the corresponding process.
Theta determine the granularity of perturbation discretization, and it will be adaptively changed in the search iteration.
In this section, extensive experiments are conducted to evaluate the effectiveness of the proposed GAQA attacks son DNN models.
Given the sorted population Theta for the Theta-th iteration, the fitness value Theta of the solution Theta is the highest.
PSO address the optimization problem by simultaneously moving the particles in the searching space based on the corresponding fitness values.
Training high-dimensional data require larger models.
ASR.
In Section III, the query-based black-box attack has been formulated as a multi-objective optimization problem, which is obviously a non-convex and discrete optimization problem.
In this section, we valuate the effectiveness of our method on the non-defensive models from three perspectives: neural network architecture, Theta norm and dataset.
In contrast to white-box attack, black-box attack has a wider search space because it has no knowledge of the specific distribution of the high-dimensional space.
Then  we define an area Theta  named convex space around Theta in high-dimension space, it satisfies equation.
This paper exploits a group of Theta to reproduce a batch of perturbations.
