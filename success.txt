
Therefore, our method has greater ASR and lower MQ on different neural network architectures.
Therefore, we only need to optimize the second part to find perturbations with high attack evasiveness.
For comparison, we valuate each operator of GAQA on the non-defensive model  and the defensive model .
Although white-box attacks have been evaluated successful, they cannot achieve high attack performance in practical applications where the information of victim models and training data are definitely not disclosed to the adversarial attackers.
Another way to defend against attack is to construct a robust model .
Graph Embedding Models  ,  elaborates the expressive power of deep learning on graph-structured data, have achieved remarkable success in various domains, such as drug discovery ,  social network analysis , , computer version , medical imaging , financial surveillance , structural role classification  and automated machine learning .
DNNs are designed to learn the high-level features using layer-by-layer data processing in high-dimension space, similar to the information flow of neurons in living organisms.
IT is devised to reduce the model sensitivity to perturbations on original images.
We assume Theta as the Theta-th solution in Theta-th generation and  Theta as the Theta-th solution in Theta-th generation.
In contrast to white-box attack, black-box attack has a wider search space because it has no knowledge of the specific distribution of the high-dimensional space.
First, GAQA takes Theta to initialize the perturbation population.
Compared with the black-box methods, our method has Theta increase in ASR.
Specifically,  Theta can be calculated according to equation.
After formulating the poison attack as a multi-objective optimization problem, which is a non-convex, and a discrete optimization problem, finding the optimal poisoned examples to attack embedding models is extremely difficult due to the explosive search space and potential gradient traps.
Similar to card shuffling in card-play games, we randomly select the genes from their fathers to generate new solutions.
We start our experiments on the CIFAR-10 dataset with Theta norm.
Query stage, the adversarial examples  are feed to the victim model to get the corresponding confidence values of prediction classes.
We chose Theta and Theta norm to evaluate the effectiveness of our method on CIFAR-10 with ResNet.
Theta is related to the speed Theta in 3rd generation, the best-so-far perturbation for the first particle , and the best perturbation in the 3rd generation .
STATE Calculate Theta loss according equation.
Jumping process  will further used to generate non-local optimal solutions when the number of iterations reaches at the predefined threshold Theta.
Second, ablation study is presented to demonstrate the efficiency of each step of our GAQA in Section V.
The average MCSD of GAQA is Theta, Theta, Theta, Theta and Theta of those of APGD-CE, ZOO, Square, DeepFool, and GenAttack, which means that our GAQA has a great evasiveness on the big-scale datasets.
PSO-Jump, which takes a set of perturbation particles  as the input.
In Section V, extensive experiments are conducted to evaluate the performance of proposed method.
Theta and Theta are limited to the number of population Theta.
The better Theta of offspring will be remained after superiority-driven probabilistic selection.
To improve the convergence of GAQA, we choose to upgrade the reproduction-related parameters according to the predication of searching overhead.
So in SAT, we use equation.
In Section VI , extensive experiments are conducted to evaluate the performance of proposed method.
In the attack epoch, SAT will calculate feature weight firstly.
Next, SAT will initial the perturbation and start attack loops.
For image classification tasks, well-designed AEs is capable of fooling DNN models with wrong predictions while being imperceptible to human naked eyes.
It is difficult to design an efficient algorithm that can generate adversarial examples in the discrete space.
In addition to the strong ability of model prediction, we assume the victim DNN models are deployed with certain defensive protections to ensure their robust to adversarial attacks.
For the evolving procedure, PSO-Jump will update the position of each particle for Theta times .
PSO-Jump finally will return the updated perturbations Theta to GAQA for GA-based evolution .
Due to the strong randomness of the shuffle-based-crossover, shuffle-based-crossover expands the width of the search scope instead of the depth of the scope.
Average Queries : the average query times in the three experiments.
After that, GAQA will conduct the superiority-related probabilistic selection on the current perturbation solutions , wherein the inferior solutions will be deleted from the current generation .
The average MCSD of GAQA is Theta, Theta, Theta, Theta and Theta	of those of APGD-CE, ZOO, Square, DeepFool, and GenAttack, respectively.
Theta indicates the standard deviation of Theta and its eight adjacent points.
To sum up, our method achieves good performance on the defensive models according to the experimental results on CIFAR-10, CIFAR-100 and ImageNet.
The six attack methods can be divided into three types: GAQA, Genattack and others.
Given a set of clean  images and the attack method A, Theta is used to denote the set of AEs which successfully attack the victim model.
We have conducted to extensive experiments to evaluate the efficiency of our method.
Fixing Data Augmentation   on CIFAR-100: using generated examples to provide a greater diversity of augmentations that help enhance the image manifolds and allow adversarial training.
Our method has average Theta, Theta, Theta, Theta and Theta reduction in NED, respectively, compared with APGD-CE, ZOO, Square, DeepFool, and GenAttack.
In this paper, we use GA to address the AE generation problem since it can be inherent formulated as constrained optimization problems.
Given the input image Theta having the width Theta and the height Theta, Theta the MCSD can be obtained by equation.
For the second question, we cut the edge array into Theta fragments and splicing them together is like genetic recombination.
We evaluate the effectiveness of the proposed method on defensive models and non-defensive models in Section V and Section V.
Moreover, removing the initialize-population will increase MQ by Theta with a Theta drop in ASR.
In this paper, we have made efforts to generate adversarial examples for defensive DNN models deployed in the image-related intelligent systems.
We can observe that Theta will exceed the Theta according to equation.
Mlp-mixer is a traditional neural network, which consists of an input layer, several hidden layers and an output layer.
In this section, benchmark-based experiments are conducted to evaluate the efficiency of the proposed method.
Probabilistic selection will only take Theta time cost.
Swim-transformer is a new neural network based on the NLP transformer.
Incorporating with gradient information, decision boundary-based methods are also developed, which can push the data to the decision boundary to realize misclassification of images.
GAQA is designed to pick up certain top perturbations  for reassembling operations.
Theta is the best solution  of all solutions in the Theta-th iteration.
PSO-Jump is checked whether to be invoked by comparing Theta to the predefined threshold Theta .
We choose Mlp-mixer , Swim-transformer  and ResNet  as the non-defensive models.
Adversarial training is an useful tool to build a stronger DNN, where defenders could use attack method to generate adversarial examples and put them into training process.
As the nodes become more difficult to discriminate between their features, the downstream task models have less accuracy.
GEMs will continually train the model to get the best parameter.
The three black-box attack methods  and our method have higher MQ and AQ, since they need to estimate the evolution direction through the query model.
Theta, Theta or Theta.
In other words, the predicted Theta depends on the so-far optimal fitness and the number of iterations.
Then use the chain derivation to get feature weight.
Defenders  usually use white-box attack methods to generate adversarial examples because they have access to the parameters and structure of their model.
The ASRs of all three types have no overlap, which may be because the bigger scale datasets have the larger search spaces.
GM is also cost-expensive and not suitable for black-box attacks.
We chose UD , WDM , ODEs  as the victim neural networks.
Theta is the best solution  of the Theta-indexed solutions for the first Theta iterations.
PSO-Jump, probabilistic-selection and block-based-crossover are used to decrease the query number, leading to a performance degradation on the non-defensive models.
Since GAQA can generate better adversarial examples according to equation.
Theta is probability of the edge  being chosen.
PSO address the optimization problem by simultaneously moving the particles in the searching space based on the corresponding fitness values.
Secondly, those dirty graphs will be pass to the victim model and valid model to get embedding result.
The attack process could be divided into five steps.
Attack Successful Ratio : the ratio of incorrect classification in the input images.
To guide the searching direction of GAQA, a fitness function should be designed to evaluate the quality of each solution.
Afterwards, PSO-Jump will evaluate the fitness value Theta, and check whether it is greater than Theta .
Considering the linear characteristics of DNNs, FGSM  is proposed to generate AEs using on-step gradient updation on image pixels.
Each solution could have the average perturbation range as Theta for Theta solutions of Theta.
In this paper, we propose the elites-preferred probabilistic selection to choose solutions for the coming iterations in our GAQA.
Theta and model classify it into Theta, which is called positive examples.
Theta determine the granularity of perturbation discretization, and it will be adaptively changed in the search iteration.
For the situation of failed AE , Theta is less than zero.
Similarly, the evolutions of Theta, Theta and Theta for the 4th generation can be conducted.
UD, WDM and ODEs are based on CIFAR10.
Note that PSO-Jump is described in the following paragraph.
For the situation of successful AE attack, the value of the first part is fixed to  Theta according to the Theta operation on it.
AE generation.
ResNet is a widely used neural network, which contains identity short-cut connections.
The solution set of this  problem contains many locally optimal solutions.
Less MCSD means that our adversarial examples have less high frequency signals, which makes our method unlikely to be detected by identification modules or cleared by the compression modules.
For any point Theta, it satisfies equation.
ASR, MQ and AQ comparisons on different nerual network architectures.
Assume that the defenders know the model structure and can deconstruct the DNN model to get the weight parameters.
Our method achieves a Theta increase in ASR and respectively decreases AQ and MQ by Theta and Theta compared with the three black-box methods.
Adversarial example recognition relies on two networks: identification and elimination  model.
Minimum Attack Set : the minority attack methods set which could cover other attack methods completely.
Then, this paper proposes a query-efficient AE attack based on Genetic Algorithm  and Particle Swarm Optimization  to address the perturbation optimization problem.
LTD and FDA are based on CIFAR100.
This section conducts ablation experiments to test the effectiveness of our method.
APGD-CE , ZOO , Square-Attack , DeepFool , GenAttack .
It would be good policy to produce new offspring  in the direction of perturbation-direction of input data.
Since this paper only considers to generate adversarial examples for images of general size, it would be a challenging work to extend our searching framework to support the generation of adversarial examples for super large images.
Due to the inherent characteristics of gradient-free and adaptive query, we only need to deal with detection-based defensive mechanisms based on input transformation while ignoring the defensive mechanisms of adversarial training and gradient masking.
This is a high-dimension coordinate system in input space.
Low Temperature Distillation   on CIFAR-100: using the knowledge distillation framework to generate the desired soft labels.
Based on the evolution matrix for the first three generations, the solutions of 4th generation can be produced.
Due to their mutual boosting effect, our method is not only prevented from falling into the gradient trap, but also speeds up the convergence of the search process.
We use it to construct dirty edge Theta and dirty node attribute Theta by the equation.
For convenience we define edge perturbation Theta and node perturbation Theta.
To be specific, SAT performs edge perturbations for those sensitive nodes.
PSO is designed to an iterative searching algorithm by imitating the food-finding process of a flock of birds.
Initiate the perturbation solutions Theta via equation.
Next we will pass the feature and feature weight to SAT to get loss.
Some white-box attacks only search at one convex space which contains Theta.
As a supplementary work, this paper proposes a sensitivity-aware attack framework in order to target attacks on graph embedded models that use structures such as Graph Attention Network , graph convolutional Network  as neural network components.
Crossover operation is used to mix the genes from two different perturbations in order to generate the greater perturbation with lower loss.
In this paper, we aim to generate a poisoned training dataset which will decrease the performance of graph embedding.
In Section IV, the detailed design of query-efficient GA attack is given.
In this section, we list the basic symbol of this paper and use it to describe the work process of GEMs and following attack process.
To make AE attacks imperceptible, according to equation.
The compression phase Theta will compress an input image.
Therefore, GAQA has a better attack capacity even in a poor start position, but it will take more steps to achieve the same performance.
Well Designed Model   on CIFAR-10: reducing capacity via depth or width at the deeper layers to improves adversarial robustness.
SAT is designed to iteratively evolve the perturbations clean graph, with the purpose to successfully attack the graph embedding model.
It indicates that our method with well-designed operators has a strong searching capacity in vast space.
Then, we assign a filter probability for each solution.
Therefore, this operator helps GAQA to find the adversarial examples quickly.
However, due to the weak interpretability, DNNs has the inherent vulnerability to Adversarial Example  attacks  .
Let Theta, searching with multi-granularity in the direction of Theta can help to find the optimal solution.
Particle Swarm Optimization  can obtain optimized solutions in a large stochastic searching space by imitating the food-finding process of a swarm of birds .
This is because the white-box attacks have the gradient information to modify the perturbation direction whereas our method explores the direction.
In this equation, Theta is the model weight of encoder.
Training high-dimensional data require larger models.
It has the high probability to increase the fitness value if changing the perturbation of  Theta  towards the direction Theta.
Node attribute Theta and truth label which could be predicted by any downstream task model Theta.
So we compute the sensitivity for nodes and edges separately, which is then used to update the node and edge perturbations.
Theta is decreasing with the growing of Theta.
GM is to force DNN models to have zero-close gradients, thus reducing the perturbation sensitivity to DNN models.
GAQA has achieved a Theta increase in ASR, and respectively decreased AQ and MQ by Theta and Theta, compared with the three black-box methods .
Based on the predicted Theta, Theta can be calculated by the following equation.
To implement white-box attacks, the adversarial attackers are assumed to know the full knowledge of model architecture, model parameters and training data of the victim DNN models.
In this paper, we aim to fast generate AEs via query-based black-box method to attack defensive DNNs deployed in MLaaS.
Specifically, the calculation of Theta can be referred to equation.
Removing the PSO-Jump will increase MQ and AQ.
Black-box AE attacks are also seriously threatened to DNNs .
We use Theta and Theta to denote the set of elite solutions and the set of inferior solutions in the Theta-th generation, respectively.
Normalized Euclidean Distance : the difference between the original images and the adversarial images.
To facilitate the attack in practice, we presented a query-efficient black-box method, named GAQA, to generate adversarial examples.
Given the benign input Theta with the class label as Theta, the perturbed Theta is defined as an AE if misclassified to the label Theta.
In this section, we valuate the effectiveness of our method on the non-defensive models from three perspectives: neural network architecture, Theta norm and dataset.
The original training dataset is unknown to defenders, meaning that the defense strategy cannot be designed from the perceptive of the dataset.
The objective of attack coverage could not be represented in the fitness function, since it depends on the experimental comparison with other attack methods.
First, the query efficiency of GAQA is much higher than whitebox attacks, although this is reasonable because of the zeroknowledge of victim models.
The specific values of Theta and block size will be adaptively changed during each iteration, thus improving the convergence of QAGA.
As the primary group of machine learnings, Deep neural networks  are immense popular in regression tasks and classification tasks of emerging intelligent systems, especially for image processing systems.
Illustration of PSO-based perturbations evolution.
The construction is shown as equation.
However, these methods are query-intensive and computation-expensive, thus limiting their applications in real-world applications.
This could guarantee all genes of Theta are independently inherited from fathers.
First, the experimental setup is given in Section V.
The gradient descent algorithm is highly efficient for solving convex problems, but at the same time, it is easy to fall into local optimal solutions when solving non-convex problems, and it is necessary to initialize the start of the search several times to solve a better solution.
Consequently, we define the fitness  of each perturbation solution by equation.
Since the non-defensive models have many weaknesses, attack methods have fewer queries compared with attacking the defensive models.
The two white-box attack methods  and our method can achieve Theta ASR.
Due to the explosive search space, it is extremely difficult to find the optimal AE to attack defensive DNN models.
Before the searching iteration, GAQA needs to construct the initial population.
We use three dataset including CIFAR-10, CIFAR-100 and ImageNet to evaluate the effectiveness of the proposed method on defensive models and non-defensive models.
In Stage , new solutions  will be generated via Reproduction operators including Perturbation-varied reproduction, Block-based crossover, and Shuffle-based crossover.
FL and RAT are based on ImageNet.
But the node update may exceed the limits, we need to revise it to satisfy the attack limits.
Section presents the threat model and formulate the design to a multi-objective optimization problem.
Adversarial Training , Gradient Masking  and Input Transformation  and Theta.
We assume to predict the remaining iterations when GAQA has searched for 100 iterations.
So we proposed feature sensitivity to enhance SAT's Effective.
A Defensive DNN model is defined as Theta, which is able to alleviate the impact of perturbed input Theta with the defensive policy Theta.
GAQA has more queries than the two white-box methods .
During the searching iteration, the parameters related reproduction operators need to be updated.
The best solutions for all particle positions  are also updated according to the fitness evolution matrix.
The fragment in the same position in Theta comes from a different parent array than Theta.
While contrastive SSL methods have experienced an emergence in the past two years, such as MoCo ,  the well-established BERT  as well as the very recent MAE  in CV.
Therefore, our approach has stronger searching capacity and higher ASR.
Section V-B.
In Section V, the detailed design of query-efficient GA attack is given.
The newly generated solution Theta in Theta-th iteration is related to the solution Theta and its moving speed , which is formally expressed by equation.
The adversaries have the right of accessing to DNNs, and mostly exploit back-propagation methods to obtain the gradient information of DNN models, thus generating white-box AEs to threaten the victim models.
In this section, extensive experiments are conducted to evaluate the effectiveness of the proposed GAQA attacks son DNN models.
This paper will focus on dealing with IT-based detection and defense within MLaaS.
Theta decrease in the number of queries.
Therefore, we can conclude that the PSO-Jump of our GAQA is effective.
With the purpose of preventing the disappearance of elite solutions and ensuring the non-decrease of the fitness function, the solutions with high fitness values are generally expected to be kept in the next generation.
We fulfil this requirement by using the probabilistic selection function, donated as equation.
Note that, each element of the matrix chromosome Theta can change independently.
Theta is designed to decrease with the increase of Theta to guarantee the high probability to select elite solutions, as shown in equation.
To make the attack more practical, we exploit query-based black-box method to generate image AEs.
SAT use both gradient descent and genetic algorithms to update the node perturbations and edge perturbations.
At the same time, we make edges with higher edge weights more likely to be selected.
But some white-box algorithm may have different coverage compared with black-box attack.
Given a clean image, the corresponding AE depends on the perturbation on each pixel of the image.
Since feature-squeezing and image-compress are two most widely used input transformation policies, we must try our best to guarantee the generated AEs can stealthy pass the corresponding process.
It will iterativly update several edge perturbations which means SAT will search at several positions and choose the best.
Different to traditional GA, adversarial example-specific reproduction operators are well designed to improve search efficiency of GAQA.
The average MCSD of GAQA is  Theta, Theta, Theta, Theta and Theta of those of APGD-CE, ZOO, Square, DeepFool, and GenAttack, respectively.
For instance, the produce of Theta depends on the solution Theta in the position Theta of 3rd generation and the speed Theta according to equation.
Then SAT will update the node perturbation and edge perturbation respectively.
Otherwise, PSO-Jump continues the evolving procedure by updating Theta  and  Theta by Theta .
Some existing attacks  consider to restart the searching by dropping all the perturbations, which is waste of the searching efforts.
Along with the fast development of AE attacks, the robustness of DNNs has received increasing concerns.
ASR.
However, it is not suitable for the search framework of GAQA, because we always expect to keep the perturbations better fitness values even with mutation operations.
In addition, most of existing AE attacks including both white-box and black-box methods ignore to generate AEs for defensive DNNs in the scenarios of MLaaS.
Mean Convolution Standard Deviation : the smoothness of a adversarial image.
We use CIFAR-10, CIFAR-100 and ImageNet to test evaluate the effectiveness of our method on ResNet with Theta norm.
This paper exploits a group of Theta to reproduce a batch of perturbations.
We define Theta as mean convolution standard deviation to evaluate the high frequency signals of AE, which calculates the standard deviation of a pixel point and its eight adjacent points.
Especially for defensive models, our methodcan obtain top attack performance with the lowest query costcompared to black-box attacks.
Therefore, it is practical to set a threshold  for the intolerable searching iterations.
The query operation of the victim model can be defined as the function Theta, within which Theta returns the confidence of recognizing input Theta as class label Theta.
It may be because that Genattack has no jump operator and adaptive process.
Lastly, we define the problem shown as equation.
However, keeping certain weak solutions into the next iteration is also absolutely necessary since they also have certain superior genes in their chromosomes.
In other words, the requirement satisfied adversarial example can not be generated even with high time overhead.
Similarly, we consider to choose the solutions in elite population and inferior population to implement the shuffle-based crossover.
Sort Theta by the decrease order of fitness.
SAT get the feature and use it to train the downstream task model.
Our method has average Theta, Theta, Theta, Theta and Theta reduction in NED, respectively, compared with APGD-CE, ZOO, Square, DeepFool and GenAttack.
Benchmark-based experiments on CIFAR-10, CIFAR-100 and ImageNet-1K are conducted to evaluate the efficiency of our method in both defensive and non-defensive scenarios.
As a flexible searching framework, GA can be designed to support both single-objective and multi-objective optimization problems.
The Theta-th solution in Theta-th generation  with higher fitness Theta function values are more likely to be selected in the next generation Theta.
Theta is the perturbation bound of Theta-norm.
To sum up, our method achieves better performance on the non-defensive models according to the experimental results of different neural network architectures, Theta norm and datasets, which demonstrates that our method is suitable for different situations.
In general, evolutionary operators of selection, crossover and mutation are utilized to breed the next-generation population.
Given the sorted population Theta for the Theta-th iteration, the fitness value Theta of the solution Theta is the highest.
On the contrary, black-box attacks are assumed to be zero-knowledge of architecture, parameters or any other settings of targeted DNN models.
AT is expensive to obtain holistic AEs and cannot guarantee its effectiveness facing emerging AEs, especially black-box generated AEs.
Defenders  could use image compression to reduce high-dimensional data to low-dimensional data.
Similar to GA's searching framework, GAQA is designed to iteratively evolve the perturbations on clean images, with the purpose to successfully attack the defensive victim DNN model.
We assume the distance between any two consecutive perturbations are the same.
The high-quality genes from low-score chromosomes will be filtered out, whereas the high-quality genes from high-score chromosomes are mostly kept for the next searching iteration.
GAQA initializes the perturbation population and search-related parameters .
With the purpose of alleviating the vulnerability to AE attacks, certain mechanisms are emerging to improve the defensive performance of DNNs including AE detection and recognition , adversarial training of DNNs  and image compression  in the image domain.
The crossover and mutation operator are designed to increase the diversity of population while the selection operator is used to find globally better solutions Theta in the search space.
For example, given Theta as Theta, the expected number of chosen chromosomes can be calculated to be Theta for the population with Theta solutions.
A lower loss can indicate that the  embedding model's performance on a downstream task is still poor even if it is trained well enough.
We propose a GA-based query-efficient attack method to generate image AEs to breakthrough victim models with defensive mechanisms.
The mutation probability Theta and shuffling probability Theta also need to be updated with the predicted Theta.
This is reasonable since white-box attacks need to know the detail information of model architecture, model parameters and training data of the victim DNN models.
PSO-Jump will terminate the PSO evolving when generating one effective AE.
As a supplementary work, this paper approaches to implement black-box AE attacks on defensive DNN models deployed in servers like MLaaS.
Section II describes preliminaries work.
As the future work, it is worthy of doing the following researches.
The identification and elimination strategy is applied to defend against potential adversarial example attacks.
Then we need to calculate the probability of being chosen, for an edge array, we choose Theta edges which haven't appeared in the array to replace the array element randomly.
Median Queries :  the median query times in the three experiments.
We choose LTD  and FDA  as the victim neural networks.
Compared with the three black-box attack methods, our method has greater ASR and lower MQ.
Genattack has the smallest CR among the six attack methods, which may be because it has no adaptive function and well-designed reproduction process.
Well-designed evolutionary algorithms have been used for image generation , image classification   and neural architecture search .
To sum up, removing any operator will lead to the drop of ASR in both non-defensive and defensive models.
Consequently, PSO-Jump will take the time overhead of Theta.
Its success has been largely built upon relatively complicated training strategies.
It is of critical importance to construct the initial population Theta with the purpose of improving the search efficiency.
In generative embedding model, we noticed sometimes the embedding result of each node has a relatively close proximity, which may make it difficult for downstream task models to distinguish between these nodes, resulting in performance degradation.
ASR, MQ and AQ comparisons on different datasets.
For example,  Sun  use meta-gradients to solve the bilevel problem underlying training-time attacks, essentially treating the graph as a hyperparameter to optimize.
GAQA can reduce Theta, Theta, Theta, Theta and Theta in NED, respectively, compared with APGD-CE, ZOO, Square, DeepFool, and GenAttack in three defensive models.
This section introduces the preliminaries.
Image compression used to reduce input space.
Theta is the dimension of input Theta, Theta is the bound of Theta-norm to escape human perception.
We can conclude that our GAQA is suitable to check the robustness of neural networks.
To sum up, removing any operator will lead to the drop of ASR in the non-defensive or defensive models, which demonstrates that each operator of GAQA plays a role in the searching process.
After getting variance, we use Theta as an intermediate derivation variable, and use the chained derivation rule to find the sensitivity of the downstream task classifier to the variance of each feature.
We choose different neural network architectures including Mlp-mixer , Swim-transformer  and ResNet  to test the effectiveness of our method on the non-defensive models on ImageNet with Theta norm.
Meta attack, Dice attack, Random attack , embed attack.
Those processes are shown in equation.
Considering a complex DNN Theta  with numerous parameters, it has a powerful  ability to fit the input signal.
As one popular method, Genetic Algorithm  is popular to search optimal solutions for constrained optimization problems.
Update adaptive parameters Theta, Theta, Theta via equation.
Different to existing works, in this paper we are interested in the generation of AEs for DNNs with defensive mechanisms.
In other words, the objective of attack evasiveness needs to be improved only if the AE attack is effective.
PSO for our AE search problem.
Based on the experiments, we can seethat the query cost in ImageNet is higher than that for thedataset of CIFAR-10 and CIFAR-100.
To improve the convergence, GAQA conducts the adaptation operation to update the reproduction-related parameters according to equations.
We expect to initiate the perturbations of all solutions to fill the searching space uniformly.
Theta represents the maximum percentage of change of each node, for example, if Theta equals to Theta, it means the node attributes won't change by more than Theta.
First, the number of discrete perturbations, Theta, needs to be refined.
The perturbation matrix for each father solution is first split into a number of square blocks.
Therefore, it is important for defenders to find  adversarial examples as much as possible.
CR results on the two defensive models.
From another point of view, defenders could reduce the decentered neighborhood.
Given Theta as the minimal value of attack effectiveness , the fitness function is transformed to optimize the attack evasiveness while guaranteeing the attack is effective.
In case of non-defensive models, our method can successfully attack state-of-the-art network architectures including Mlp-mixper and Swim-Transformer.
Deep Neural Networks  have been immensely deployed into artificial intelligence-driven applications , ranging from identification recognition to environment surveillance and to smart robot applications.
To deceive the perception of human eyes, each element of the perturbation has the bound of Theta.
For each edge, we need to estimate its weight and determine the probability that it  be deleted or added.
In Section III, the query-based black-box attack has been formulated as a multi-objective optimization problem, which is obviously a non-convex and discrete optimization problem.
Our method has more MQ and AQ on the large-size datasets.
Comparing with white-box attacks, they are more practical since they are assumed to be zero-knowledge of model architecture, parameters and the training data.
The Theta function will return the variance for each row for a two-dimension matrix.
In this section, we conduct the ablation experiments to test the effectiveness of our method.
According to the procedure of GAQA, the time overhead consists of eight parts during the GA search framework.
More specific, this paper aims to deploy a query-based gradient-free black-box attack on MLaaS, which can adaptively upgrade the attack strength of adversarial inputs according to the returned confidence values of all classes.
With the updates of searching parameters, GAQA can adaptively work during the searching iterations and consequently quickly converge to find the near-optimal global solutions.
Theta represents the existing attack methods.
Besides the objective of attack effectiveness, we need to evaluate the attack coverage ratio of the proposed black-box attack method.
The smaller NED means that the adversarial examples generated by our method are more similar to the original images.
The hyper-parameters of SAT are given in TABLE I.
In addition, we use the 0-1 matrix Theta to represent the gene-shuffling selection of each selected father chromosome, where each element Theta of Theta  is set to 1 with the probability of Theta.
We use the degree of the node to estimate the sensitivity of the victim model to the attributes of the node.
Shanqing Yu   proposed a genetic algorithm-based Euclidean distance attack strategy  to attack the network embedding model.
The equation is shown as equation.
The quality of population members is evaluated by a fitness function.
According to the pseudo code of PSO-Jump, the main time overhead depends on the Theta iterations to calculate the speed Theta and the perturbation Theta for particle Theta, which takes time overhead of Theta.
Following that, BIM   is further designed to generate better AEs by iteratively using FGSM.
But recently some paper like graphMAE  can consistently generate outperformance over both contrastive and generative state-of-the-art baselines.
Besides, the vast searching will decrease the efficiency of out proposed SAT.
Although Genattack is a genetic algorithm, it has poor performance.
First, the solutions in the current generations are sorted by the decrease order of their fitness values.
Such as poison and evasion attack, black-box and white-box attack.
ASR, MQ and AQ comparisons on different Theta norm.
Ordinary Differential equationuations   on CIFAR-10: imposing constraints to ensure that all eigenvalues of the Jacobian matrix of the neural ODE layer have negative real parts, when each classification class converges to its own equilibrium points.
Theta is the maximal fitness value for all solutions according to equation.
Our approach is attacking a defensive model.
APGD-CE and DeepFool are white-box attack methods while ZOO, Square-Attack and GenAttack are black-box attack methods.
To obtain the fitness value , we need to sort the confidence values of Theta labels .
Meanwhile, it attracted researchers use attack approaches to test the robustness of it  .
Section II describes related work.
Theta and Theta.
As a prominent branch of AE attacks, a great number of white-box attacks have been developed .
Adversarial example  attacks are typically launched by maliciously crafted inputs, and aim to let DNN models to misbehave.
Most of the graph embedding models nowadays are trained with Self-supervised learning , which can be generally categorized into generative and contrastive methods , has found widespread adoption in computer vision  and natural language processing .
From the view of defense, it would be interesting to find the weakness of the deployed models using our method, and then fix the vulnerability to enhance the model robustness.
When applying mutation on the set of perturbations, it will result in certain high-quality genes and inferior genes.
Theta is increased after the PSO-Jump process.
Since Theta is much less than Theta and Theta, time complexity of PSO-Jump can be obtained as Theta.
Theta, Theta and Theta.
Although we have introduced certain mechanisms to avoid the searching into local optimal space, there still has the possibility to fall into the local optimum after a large number of evolving iterations.
We calculate the variance of each feature dimension and multiply them by the Theta matrix to get the loss.
When the estimated steps exceed the threshold, the iterative process of PSO will be performed.
For simplicity, we calculate them with the same following equation.
Meanwhile, our approach has the same ASR with the white-box attack methods while our method has lower queries compared with other black-box attack methods.
In contrast to white-box attack, block-box attack has a wider search space, because it has no knowledge of the specific distribution of the high-dimensional space around the original example.
The Theta function  is to evaluate the performance of  downstream tasks model Theta, Theta is the true label of graph Theta in downstream tasks.
Then PSO-Jump calculates the perturbation of Theta according to  Theta and Theta  .
In natural selection, the superior offspring may be born with elite fathers and inferior fathers.
Adaptive mutation is designed to improve the diversity of the perturbations in Stage .
TLM  and RAT  as the victim models.
Unlabeled Data   on CIFAR-10: using unlabeled data to bridge the sample complexity gap between standard and robust classification.
Theta must be limited.
Due to the bigger search space of the large-size images, our method needs more queries to estimate the evolving direction.
However, our GAQA has fewer queries compared with the three black-box attack methods.
The effectiveness of attack methods is evaluated by seven metrics.
However, the research to generate AEs using evolutionary algorithms is seriously overlooked for defensive DNNs.
The values of  Theta and Theta will increase with the number of Theta growing.
The first part is related to the objective of attack effectiveness, whereas the second part focuses on the objective of attack evasiveness.
Theta.
Due to high time overhead to find the optimal Theta for each solution Theta, we choose to search for the near-optimal Theta only for Theta in each generation, thus reducing the complexity of the query process.
Perturbation-varied reproduction is designed to generate Theta new perturbations, thus it costs Theta.
Then  we define an area Theta  named convex space around Theta in high-dimension space, it satisfies equation.
Theta is calculated by the following equation.
Revisiting Adversarial Training   on ImageNet: using a weaker and cheaper adversary by FGSM to train a defensive model with higher robust accuracy.
